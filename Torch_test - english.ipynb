{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsQ4UPbpssDjssn24dRIhz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "575c46aa84794fb8b3674373bbebcf8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44e7ac9101f94ef698913ba80a3b5341",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51ef0f156e68484b83b354a52a5fc170",
              "IPY_MODEL_0941ddd468df4626b89ff5d96f7125ca",
              "IPY_MODEL_4e7ec4a90708493598c1319af49b6d03"
            ]
          }
        },
        "44e7ac9101f94ef698913ba80a3b5341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51ef0f156e68484b83b354a52a5fc170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea287ed43df941edb13f7b135bc50ce4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e20c360d24e42628a0fc0f3e1a2f08f"
          }
        },
        "0941ddd468df4626b89ff5d96f7125ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6155e19e93d4e7bbd173ee223493059",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e0d85a570b043f88cd939d8c09b58ed"
          }
        },
        "4e7ec4a90708493598c1319af49b6d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a56414ab972c4a0797be8121ec64b585",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 22526088.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ddaf296ea45423cb13b42a2205d786c"
          }
        },
        "ea287ed43df941edb13f7b135bc50ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e20c360d24e42628a0fc0f3e1a2f08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6155e19e93d4e7bbd173ee223493059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e0d85a570b043f88cd939d8c09b58ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a56414ab972c4a0797be8121ec64b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ddaf296ea45423cb13b42a2205d786c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da14823408f64500bfb6eff1e374456d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6442a6b837a84bb6adf0780040719538",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b2a90377c7a43ec875eaee18a4d2e21",
              "IPY_MODEL_1d49baefdb5043328f225ce64811e209",
              "IPY_MODEL_6c753af3a91842a8900124981636f550"
            ]
          }
        },
        "6442a6b837a84bb6adf0780040719538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b2a90377c7a43ec875eaee18a4d2e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_172a7dc02ed2454397a6ddb0668f7b2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00abcd83ceee4552b0cfe370e5c5a134"
          }
        },
        "1d49baefdb5043328f225ce64811e209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3de915d072774fcfbf7c76f16da67bff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e38b9b716bf4ff6a9913307395f692a"
          }
        },
        "6c753af3a91842a8900124981636f550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_542ec6088a844ea49dff8e95d6168098",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 478474.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53a68327fcdd42d0a822fc01e2f18649"
          }
        },
        "172a7dc02ed2454397a6ddb0668f7b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00abcd83ceee4552b0cfe370e5c5a134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3de915d072774fcfbf7c76f16da67bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e38b9b716bf4ff6a9913307395f692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "542ec6088a844ea49dff8e95d6168098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53a68327fcdd42d0a822fc01e2f18649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b780ffb328741288a30f64179531641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ffae8e83cc645ec93936138fd3122b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b228023e0554c1cb707060a69b1490e",
              "IPY_MODEL_5bbc9c8131dc44c8b4aa70ee9811ed6d",
              "IPY_MODEL_2bcf2c8cb13f4717bd1795e8cd61a71d"
            ]
          }
        },
        "3ffae8e83cc645ec93936138fd3122b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b228023e0554c1cb707060a69b1490e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d67cb5814ad94602a636634f924390d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f461dcfeb83457e94ba48fe428e6b9b"
          }
        },
        "5bbc9c8131dc44c8b4aa70ee9811ed6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e992f5c44bd4300a4ac6e04e522ea13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45672dbf30db408c8eaddaa4fb726dab"
          }
        },
        "2bcf2c8cb13f4717bd1795e8cd61a71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c9012af404843b38f218e637a755d12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 9602891.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4784e1eeffa4b38b1890283c2147824"
          }
        },
        "d67cb5814ad94602a636634f924390d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f461dcfeb83457e94ba48fe428e6b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e992f5c44bd4300a4ac6e04e522ea13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45672dbf30db408c8eaddaa4fb726dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c9012af404843b38f218e637a755d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4784e1eeffa4b38b1890283c2147824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b0179d524db4b23b9e39def07f956d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3f24e757abe424d8560242127662309",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_425c38c6cbfc4e8fbafac349daf45c23",
              "IPY_MODEL_817c8669a9d5462f92ee5379f0889e76",
              "IPY_MODEL_6024248306844ddbbee16cfc6fee1280"
            ]
          }
        },
        "f3f24e757abe424d8560242127662309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "425c38c6cbfc4e8fbafac349daf45c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_805237ee39d24e88a3ba4bd3a60138be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7832e37e26343beb58d78768800e3a5"
          }
        },
        "817c8669a9d5462f92ee5379f0889e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffd9b8ae648b46159741d81331cebddb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83f556b8dfa44b65b4ba246bb4722851"
          }
        },
        "6024248306844ddbbee16cfc6fee1280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b9441491934428d914333dd1a91e520",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 123152.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50dc8975ab82489bb640c273f82206ef"
          }
        },
        "805237ee39d24e88a3ba4bd3a60138be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7832e37e26343beb58d78768800e3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffd9b8ae648b46159741d81331cebddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83f556b8dfa44b65b4ba246bb4722851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b9441491934428d914333dd1a91e520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50dc8975ab82489bb640c273f82206ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyNDjhA6izLa"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import scipy.misc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use MNIST datasets to learn basic of MLP neural network. They contain image samples of written numbers. It perfectly suits study over simple neural networks."
      ],
      "metadata": {
        "id": "1nsPAoLRAaVb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5dyl1ZjNOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "575c46aa84794fb8b3674373bbebcf8d",
            "44e7ac9101f94ef698913ba80a3b5341",
            "51ef0f156e68484b83b354a52a5fc170",
            "0941ddd468df4626b89ff5d96f7125ca",
            "4e7ec4a90708493598c1319af49b6d03",
            "ea287ed43df941edb13f7b135bc50ce4",
            "9e20c360d24e42628a0fc0f3e1a2f08f",
            "f6155e19e93d4e7bbd173ee223493059",
            "4e0d85a570b043f88cd939d8c09b58ed",
            "a56414ab972c4a0797be8121ec64b585",
            "6ddaf296ea45423cb13b42a2205d786c",
            "da14823408f64500bfb6eff1e374456d",
            "6442a6b837a84bb6adf0780040719538",
            "3b2a90377c7a43ec875eaee18a4d2e21",
            "1d49baefdb5043328f225ce64811e209",
            "6c753af3a91842a8900124981636f550",
            "172a7dc02ed2454397a6ddb0668f7b2f",
            "00abcd83ceee4552b0cfe370e5c5a134",
            "3de915d072774fcfbf7c76f16da67bff",
            "0e38b9b716bf4ff6a9913307395f692a",
            "542ec6088a844ea49dff8e95d6168098",
            "53a68327fcdd42d0a822fc01e2f18649",
            "3b780ffb328741288a30f64179531641",
            "3ffae8e83cc645ec93936138fd3122b9",
            "0b228023e0554c1cb707060a69b1490e",
            "5bbc9c8131dc44c8b4aa70ee9811ed6d",
            "2bcf2c8cb13f4717bd1795e8cd61a71d",
            "d67cb5814ad94602a636634f924390d9",
            "0f461dcfeb83457e94ba48fe428e6b9b",
            "3e992f5c44bd4300a4ac6e04e522ea13",
            "45672dbf30db408c8eaddaa4fb726dab",
            "5c9012af404843b38f218e637a755d12",
            "d4784e1eeffa4b38b1890283c2147824",
            "0b0179d524db4b23b9e39def07f956d6",
            "f3f24e757abe424d8560242127662309",
            "425c38c6cbfc4e8fbafac349daf45c23",
            "817c8669a9d5462f92ee5379f0889e76",
            "6024248306844ddbbee16cfc6fee1280",
            "805237ee39d24e88a3ba4bd3a60138be",
            "c7832e37e26343beb58d78768800e3a5",
            "ffd9b8ae648b46159741d81331cebddb",
            "83f556b8dfa44b65b4ba246bb4722851",
            "8b9441491934428d914333dd1a91e520",
            "50dc8975ab82489bb640c273f82206ef"
          ]
        },
        "outputId": "ad41f942-276f-405c-8360-738d7809db38"
      },
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "575c46aa84794fb8b3674373bbebcf8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da14823408f64500bfb6eff1e374456d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b780ffb328741288a30f64179531641",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0179d524db4b23b9e39def07f956d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will load sample of our data to see if we can recognize number based on given arrays. "
      ],
      "metadata": {
        "id": "ofA_Ra9ZBMU7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeBKUGctjb_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "ed3ac6ee-77e5-4aec-b42e-e0c36863b27f"
      },
      "source": [
        "train_image, train_target = trainset[2]    #let us examine the 0-th sample\n",
        "train_image"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FBAE1740410>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrays are too long to fit in one row, therefore it is harder for human to classify numbers correctrly. If we change index numer we will see array for another image. Valuse are in range 1-256, becasue MNIST dataset uses RGB colour pallet. "
      ],
      "metadata": {
        "id": "KEpt0p_iByuI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsbGYtBijf9h",
        "outputId": "5657e07f-7091-4ee2-9d01-9e501ee35180"
      },
      "source": [
        "trainset.data[2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,  67, 232,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  62,  81,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0, 120, 180,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 126, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   2, 153, 210,  40,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 220, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,  27, 254, 162,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 222, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0, 183, 254, 125,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,  46, 245, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0, 198, 254,  56,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0, 120, 254, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,  23, 231, 254,  29,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0, 159, 254, 120,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0, 163, 254, 216,  16,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0, 159, 254,  67,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  14,  86, 178, 248, 254,  91,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0, 159, 254,  85,   0,   0,   0,  47,  49, 116, 144, 150,\n",
              "         241, 243, 234, 179, 241, 252,  40,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0, 150, 253, 237, 207, 207, 207, 253, 254, 250, 240, 198,\n",
              "         143,  91,  28,   5, 233, 250,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 119, 177, 177, 177, 177, 177,  98,  56,   0,   0,\n",
              "           0,   0,   0, 102, 254, 220,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 254, 137,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 254,  57,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 254,  57,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 255,  94,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 254,  96,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 254, 153,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 169, 255, 153,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,  96, 254, 153,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63jblweXjopd",
        "outputId": "e8917c56-e01e-4adc-dcc6-690dcbde1d0b"
      },
      "source": [
        "train_target"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To receive images in greyscale we have to normalize it. We can achive it by obtaining mean and standard deviation. After that we have to divide it by range of valuse (in case of RBG pallet it is 255)."
      ],
      "metadata": {
        "id": "ygum0MO5Ci1k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb2rmpvnju2O",
        "outputId": "038a7827-70d8-49c9-8258-5f19b4b88699"
      },
      "source": [
        "(trainset.data.numpy().mean()/255.0, trainset.data.numpy().std()/255.0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1306604762738429, 0.30810780385646264)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we create sets on wich our neural network weill learn. First we have to  standarize it and convert to torch float tensor form."
      ],
      "metadata": {
        "id": "G2v8qgkiGUju"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvNPmNv4j9eR"
      },
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [ torchvision.transforms.ToTensor(), #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "      torchvision.transforms.Normalize((0.1307), (0.3081))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2048, shuffle=False)   #we do shuffle it to give more randomizations to training epochs\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we visualize our training labels for first 5 batches."
      ],
      "metadata": {
        "id": "ZCq3zvyOHw1i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxrVvUPwj_dR",
        "outputId": "dc490066-48f3-427f-a404-1ae8c3e40e64"
      },
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "\n",
        "        if i<5:\n",
        "            print(i, \"-th batch labels :\", batch_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -th batch labels : tensor([5, 0, 4,  ..., 1, 4, 1])\n",
            "1 -th batch labels : tensor([7, 5, 4,  ..., 9, 3, 9])\n",
            "2 -th batch labels : tensor([2, 4, 9,  ..., 7, 1, 2])\n",
            "3 -th batch labels : tensor([2, 9, 0,  ..., 1, 5, 6])\n",
            "4 -th batch labels : tensor([3, 0, 1,  ..., 0, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we check number of order in batch_inputs which will be used in our neural network. Here we can see how our two-dimensional image changed to four dimensions. First determins batch size, second is index in dataset, third and fourth are size of our image."
      ],
      "metadata": {
        "id": "m5G_LT4TJNEw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5E1oNsgmkM5",
        "outputId": "644bd4f2-6877-4eb0-ac09-28ff05f96c3b"
      },
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "\n",
        "        if i==0:\n",
        "            print(i, \"-th batch inputs :\", batch_inputs.size())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -th batch inputs : torch.Size([2048, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we can make our first MLP neural network. To do so we create class using torch.nn.Module. We can create many layers. There is no universal rule on how many layers or perceptrons our network should have. To get the best results we have to experiment with few different setup. Good tip is to make our network grow first, then with each layer lower number of perceptrons. **Proceed with caution. If we give too much information to our network it will overtrain and give bad results!**"
      ],
      "metadata": {
        "id": "bu42uJbeKURS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsXpSQtbm1TS"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),   #change the last three orders in data (with dimensions 1, 28 and 28 respectively) into one order of dimensions (1*28*28)\n",
        "            torch.nn.Linear(1*28*28, 512),\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(512, 1024), #remember that entry size (first index) of our layer must be the same as size of previous layer (second index)\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(1024, 2048),\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(2048, 512),\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(512,10)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.mlp(x)\n",
        "        return out"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we use our neural network. We create object of our MLP class. "
      ],
      "metadata": {
        "id": "95i9_4bLORVJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC-0Mcxam7uX",
        "outputId": "80c0965d-1fd5-4e54-c907-e15ec35d03df"
      },
      "source": [
        "net = MLP()\n",
        "optimizer = torch.optim.Adam(net.parameters(), 0.001)   #initial and fixed learning rate of 0.001\n",
        "\n",
        "net.train() #here we inform our network it will be training in next lines\n",
        "for epoch in range(8):  #  an epoch is a training run through the whole data set\n",
        "\n",
        "    loss = 0.0\n",
        "    for batch, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "        #batch_inputs.squeeze(1)     #alternatively if not for a Flatten layer, squeeze() could be used to remove \n",
        "                                      #the second order of the tensor, the Channel, which is one-dimensional (this index can be equal to 0 only)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_outputs = net(batch_inputs)\n",
        "        loss = torch.nn.functional.cross_entropy(batch_outputs, batch_labels, reduction = \"mean\")\n",
        "        print(\"epoch:\", epoch, \"batch:\", batch, \"current batch loss:\", loss.item()) \n",
        "        loss.backward()       #this computes gradients with backward step. \n",
        "        optimizer.step()     #but this line in fact updates our neural network. \n",
        "                                ####You can experiment - comment this line and check, that the loss DOES NOT improve, meaning that the network doesn't update"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 0 current batch loss: 2.3200719356536865\n",
            "epoch: 0 batch: 1 current batch loss: 2.6219561100006104\n",
            "epoch: 0 batch: 2 current batch loss: 2.428776264190674\n",
            "epoch: 0 batch: 3 current batch loss: 2.373007297515869\n",
            "epoch: 0 batch: 4 current batch loss: 2.348644256591797\n",
            "epoch: 0 batch: 5 current batch loss: 2.3615713119506836\n",
            "epoch: 0 batch: 6 current batch loss: 2.357271432876587\n",
            "epoch: 0 batch: 7 current batch loss: 2.3340818881988525\n",
            "epoch: 0 batch: 8 current batch loss: 2.3091094493865967\n",
            "epoch: 0 batch: 9 current batch loss: 2.3047876358032227\n",
            "epoch: 0 batch: 10 current batch loss: 2.304500102996826\n",
            "epoch: 0 batch: 11 current batch loss: 2.308112144470215\n",
            "epoch: 0 batch: 12 current batch loss: 2.3073275089263916\n",
            "epoch: 0 batch: 13 current batch loss: 2.306042432785034\n",
            "epoch: 0 batch: 14 current batch loss: 2.3049612045288086\n",
            "epoch: 0 batch: 15 current batch loss: 2.3078527450561523\n",
            "epoch: 0 batch: 16 current batch loss: 2.304643392562866\n",
            "epoch: 0 batch: 17 current batch loss: 2.3034653663635254\n",
            "epoch: 0 batch: 18 current batch loss: 2.2993805408477783\n",
            "epoch: 0 batch: 19 current batch loss: 2.295527219772339\n",
            "epoch: 0 batch: 20 current batch loss: 2.293996810913086\n",
            "epoch: 0 batch: 21 current batch loss: 2.29093599319458\n",
            "epoch: 0 batch: 22 current batch loss: 2.286282539367676\n",
            "epoch: 0 batch: 23 current batch loss: 2.2823967933654785\n",
            "epoch: 0 batch: 24 current batch loss: 2.2732536792755127\n",
            "epoch: 0 batch: 25 current batch loss: 2.2634775638580322\n",
            "epoch: 0 batch: 26 current batch loss: 2.2471683025360107\n",
            "epoch: 0 batch: 27 current batch loss: 2.232003927230835\n",
            "epoch: 0 batch: 28 current batch loss: 2.1966748237609863\n",
            "epoch: 0 batch: 29 current batch loss: 2.166776657104492\n",
            "epoch: 1 batch: 0 current batch loss: 2.1373095512390137\n",
            "epoch: 1 batch: 1 current batch loss: 2.0893208980560303\n",
            "epoch: 1 batch: 2 current batch loss: 2.0364344120025635\n",
            "epoch: 1 batch: 3 current batch loss: 2.0034053325653076\n",
            "epoch: 1 batch: 4 current batch loss: 1.9477015733718872\n",
            "epoch: 1 batch: 5 current batch loss: 1.8980491161346436\n",
            "epoch: 1 batch: 6 current batch loss: 1.8874850273132324\n",
            "epoch: 1 batch: 7 current batch loss: 1.831966519355774\n",
            "epoch: 1 batch: 8 current batch loss: 1.7872223854064941\n",
            "epoch: 1 batch: 9 current batch loss: 1.7367414236068726\n",
            "epoch: 1 batch: 10 current batch loss: 1.720106601715088\n",
            "epoch: 1 batch: 11 current batch loss: 1.6802818775177002\n",
            "epoch: 1 batch: 12 current batch loss: 1.645266056060791\n",
            "epoch: 1 batch: 13 current batch loss: 1.6304839849472046\n",
            "epoch: 1 batch: 14 current batch loss: 1.5585960149765015\n",
            "epoch: 1 batch: 15 current batch loss: 1.5684802532196045\n",
            "epoch: 1 batch: 16 current batch loss: 1.4887853860855103\n",
            "epoch: 1 batch: 17 current batch loss: 1.4394869804382324\n",
            "epoch: 1 batch: 18 current batch loss: 1.4441510438919067\n",
            "epoch: 1 batch: 19 current batch loss: 1.3774901628494263\n",
            "epoch: 1 batch: 20 current batch loss: 1.374426007270813\n",
            "epoch: 1 batch: 21 current batch loss: 1.322619080543518\n",
            "epoch: 1 batch: 22 current batch loss: 1.2819749116897583\n",
            "epoch: 1 batch: 23 current batch loss: 1.272584319114685\n",
            "epoch: 1 batch: 24 current batch loss: 1.2801802158355713\n",
            "epoch: 1 batch: 25 current batch loss: 1.215730905532837\n",
            "epoch: 1 batch: 26 current batch loss: 1.157740831375122\n",
            "epoch: 1 batch: 27 current batch loss: 1.1234782934188843\n",
            "epoch: 1 batch: 28 current batch loss: 1.0989837646484375\n",
            "epoch: 1 batch: 29 current batch loss: 1.0594854354858398\n",
            "epoch: 2 batch: 0 current batch loss: 1.1270219087600708\n",
            "epoch: 2 batch: 1 current batch loss: 1.0453007221221924\n",
            "epoch: 2 batch: 2 current batch loss: 1.0193907022476196\n",
            "epoch: 2 batch: 3 current batch loss: 1.012330174446106\n",
            "epoch: 2 batch: 4 current batch loss: 1.0142602920532227\n",
            "epoch: 2 batch: 5 current batch loss: 0.9713562726974487\n",
            "epoch: 2 batch: 6 current batch loss: 1.002367377281189\n",
            "epoch: 2 batch: 7 current batch loss: 0.9681427478790283\n",
            "epoch: 2 batch: 8 current batch loss: 0.9500494003295898\n",
            "epoch: 2 batch: 9 current batch loss: 0.8872814774513245\n",
            "epoch: 2 batch: 10 current batch loss: 0.8831650614738464\n",
            "epoch: 2 batch: 11 current batch loss: 0.8665903210639954\n",
            "epoch: 2 batch: 12 current batch loss: 0.8782850503921509\n",
            "epoch: 2 batch: 13 current batch loss: 0.8538669347763062\n",
            "epoch: 2 batch: 14 current batch loss: 0.8318769931793213\n",
            "epoch: 2 batch: 15 current batch loss: 0.8292263150215149\n",
            "epoch: 2 batch: 16 current batch loss: 0.7351357340812683\n",
            "epoch: 2 batch: 17 current batch loss: 0.7205577492713928\n",
            "epoch: 2 batch: 18 current batch loss: 0.7430820465087891\n",
            "epoch: 2 batch: 19 current batch loss: 0.6975941061973572\n",
            "epoch: 2 batch: 20 current batch loss: 0.7334305644035339\n",
            "epoch: 2 batch: 21 current batch loss: 0.6580154299736023\n",
            "epoch: 2 batch: 22 current batch loss: 0.6431202292442322\n",
            "epoch: 2 batch: 23 current batch loss: 0.6387006640434265\n",
            "epoch: 2 batch: 24 current batch loss: 0.6729867458343506\n",
            "epoch: 2 batch: 25 current batch loss: 0.606239914894104\n",
            "epoch: 2 batch: 26 current batch loss: 0.5984893441200256\n",
            "epoch: 2 batch: 27 current batch loss: 0.5095435380935669\n",
            "epoch: 2 batch: 28 current batch loss: 0.4522833526134491\n",
            "epoch: 2 batch: 29 current batch loss: 0.4445776641368866\n",
            "epoch: 3 batch: 0 current batch loss: 0.5705522298812866\n",
            "epoch: 3 batch: 1 current batch loss: 0.48073163628578186\n",
            "epoch: 3 batch: 2 current batch loss: 0.5014950037002563\n",
            "epoch: 3 batch: 3 current batch loss: 0.5154429078102112\n",
            "epoch: 3 batch: 4 current batch loss: 0.5159345865249634\n",
            "epoch: 3 batch: 5 current batch loss: 0.4790510833263397\n",
            "epoch: 3 batch: 6 current batch loss: 0.5535877346992493\n",
            "epoch: 3 batch: 7 current batch loss: 0.49627190828323364\n",
            "epoch: 3 batch: 8 current batch loss: 0.49513891339302063\n",
            "epoch: 3 batch: 9 current batch loss: 0.406216561794281\n",
            "epoch: 3 batch: 10 current batch loss: 0.448504239320755\n",
            "epoch: 3 batch: 11 current batch loss: 0.4380173683166504\n",
            "epoch: 3 batch: 12 current batch loss: 0.4830823540687561\n",
            "epoch: 3 batch: 13 current batch loss: 0.4694426953792572\n",
            "epoch: 3 batch: 14 current batch loss: 0.4607296288013458\n",
            "epoch: 3 batch: 15 current batch loss: 0.4946463704109192\n",
            "epoch: 3 batch: 16 current batch loss: 0.3766472339630127\n",
            "epoch: 3 batch: 17 current batch loss: 0.34369972348213196\n",
            "epoch: 3 batch: 18 current batch loss: 0.44054684042930603\n",
            "epoch: 3 batch: 19 current batch loss: 0.37811318039894104\n",
            "epoch: 3 batch: 20 current batch loss: 0.43943995237350464\n",
            "epoch: 3 batch: 21 current batch loss: 0.3674684166908264\n",
            "epoch: 3 batch: 22 current batch loss: 0.37848153710365295\n",
            "epoch: 3 batch: 23 current batch loss: 0.37262260913848877\n",
            "epoch: 3 batch: 24 current batch loss: 0.4220641851425171\n",
            "epoch: 3 batch: 25 current batch loss: 0.37830850481987\n",
            "epoch: 3 batch: 26 current batch loss: 0.32873713970184326\n",
            "epoch: 3 batch: 27 current batch loss: 0.2982982099056244\n",
            "epoch: 3 batch: 28 current batch loss: 0.25696292519569397\n",
            "epoch: 3 batch: 29 current batch loss: 0.24747896194458008\n",
            "epoch: 4 batch: 0 current batch loss: 0.3588896095752716\n",
            "epoch: 4 batch: 1 current batch loss: 0.2818375825881958\n",
            "epoch: 4 batch: 2 current batch loss: 0.3302847146987915\n",
            "epoch: 4 batch: 3 current batch loss: 0.3402123749256134\n",
            "epoch: 4 batch: 4 current batch loss: 0.3678738474845886\n",
            "epoch: 4 batch: 5 current batch loss: 0.29829224944114685\n",
            "epoch: 4 batch: 6 current batch loss: 0.3680664896965027\n",
            "epoch: 4 batch: 7 current batch loss: 0.33633702993392944\n",
            "epoch: 4 batch: 8 current batch loss: 0.31053438782691956\n",
            "epoch: 4 batch: 9 current batch loss: 0.25488683581352234\n",
            "epoch: 4 batch: 10 current batch loss: 0.2865563929080963\n",
            "epoch: 4 batch: 11 current batch loss: 0.2802355885505676\n",
            "epoch: 4 batch: 12 current batch loss: 0.3074203431606293\n",
            "epoch: 4 batch: 13 current batch loss: 0.32453539967536926\n",
            "epoch: 4 batch: 14 current batch loss: 0.29685497283935547\n",
            "epoch: 4 batch: 15 current batch loss: 0.3270016312599182\n",
            "epoch: 4 batch: 16 current batch loss: 0.2334696650505066\n",
            "epoch: 4 batch: 17 current batch loss: 0.2152354121208191\n",
            "epoch: 4 batch: 18 current batch loss: 0.2973569929599762\n",
            "epoch: 4 batch: 19 current batch loss: 0.24692167341709137\n",
            "epoch: 4 batch: 20 current batch loss: 0.3154263496398926\n",
            "epoch: 4 batch: 21 current batch loss: 0.2353803962469101\n",
            "epoch: 4 batch: 22 current batch loss: 0.2613479793071747\n",
            "epoch: 4 batch: 23 current batch loss: 0.2599855661392212\n",
            "epoch: 4 batch: 24 current batch loss: 0.2909596860408783\n",
            "epoch: 4 batch: 25 current batch loss: 0.2659797668457031\n",
            "epoch: 4 batch: 26 current batch loss: 0.22328265011310577\n",
            "epoch: 4 batch: 27 current batch loss: 0.19344258308410645\n",
            "epoch: 4 batch: 28 current batch loss: 0.17109477519989014\n",
            "epoch: 4 batch: 29 current batch loss: 0.16275756061077118\n",
            "epoch: 5 batch: 0 current batch loss: 0.263986200094223\n",
            "epoch: 5 batch: 1 current batch loss: 0.17312726378440857\n",
            "epoch: 5 batch: 2 current batch loss: 0.21547460556030273\n",
            "epoch: 5 batch: 3 current batch loss: 0.23823261260986328\n",
            "epoch: 5 batch: 4 current batch loss: 0.265776127576828\n",
            "epoch: 5 batch: 5 current batch loss: 0.2043609619140625\n",
            "epoch: 5 batch: 6 current batch loss: 0.2521739602088928\n",
            "epoch: 5 batch: 7 current batch loss: 0.2311105877161026\n",
            "epoch: 5 batch: 8 current batch loss: 0.21331079304218292\n",
            "epoch: 5 batch: 9 current batch loss: 0.1878141611814499\n",
            "epoch: 5 batch: 10 current batch loss: 0.2130168378353119\n",
            "epoch: 5 batch: 11 current batch loss: 0.1965447962284088\n",
            "epoch: 5 batch: 12 current batch loss: 0.2235875278711319\n",
            "epoch: 5 batch: 13 current batch loss: 0.23224206268787384\n",
            "epoch: 5 batch: 14 current batch loss: 0.20978592336177826\n",
            "epoch: 5 batch: 15 current batch loss: 0.23939873278141022\n",
            "epoch: 5 batch: 16 current batch loss: 0.16529744863510132\n",
            "epoch: 5 batch: 17 current batch loss: 0.15841728448867798\n",
            "epoch: 5 batch: 18 current batch loss: 0.22097942233085632\n",
            "epoch: 5 batch: 19 current batch loss: 0.1783924251794815\n",
            "epoch: 5 batch: 20 current batch loss: 0.23503299057483673\n",
            "epoch: 5 batch: 21 current batch loss: 0.1773565262556076\n",
            "epoch: 5 batch: 22 current batch loss: 0.1940019726753235\n",
            "epoch: 5 batch: 23 current batch loss: 0.19629496335983276\n",
            "epoch: 5 batch: 24 current batch loss: 0.21847788989543915\n",
            "epoch: 5 batch: 25 current batch loss: 0.19362923502922058\n",
            "epoch: 5 batch: 26 current batch loss: 0.16100047528743744\n",
            "epoch: 5 batch: 27 current batch loss: 0.13579623401165009\n",
            "epoch: 5 batch: 28 current batch loss: 0.12081412971019745\n",
            "epoch: 5 batch: 29 current batch loss: 0.12128344178199768\n",
            "epoch: 6 batch: 0 current batch loss: 0.19568942487239838\n",
            "epoch: 6 batch: 1 current batch loss: 0.11860733479261398\n",
            "epoch: 6 batch: 2 current batch loss: 0.1570795476436615\n",
            "epoch: 6 batch: 3 current batch loss: 0.1753443032503128\n",
            "epoch: 6 batch: 4 current batch loss: 0.19602657854557037\n",
            "epoch: 6 batch: 5 current batch loss: 0.14525029063224792\n",
            "epoch: 6 batch: 6 current batch loss: 0.1865711510181427\n",
            "epoch: 6 batch: 7 current batch loss: 0.17153573036193848\n",
            "epoch: 6 batch: 8 current batch loss: 0.15783177316188812\n",
            "epoch: 6 batch: 9 current batch loss: 0.15190330147743225\n",
            "epoch: 6 batch: 10 current batch loss: 0.16898012161254883\n",
            "epoch: 6 batch: 11 current batch loss: 0.14431427419185638\n",
            "epoch: 6 batch: 12 current batch loss: 0.18360760807991028\n",
            "epoch: 6 batch: 13 current batch loss: 0.18752238154411316\n",
            "epoch: 6 batch: 14 current batch loss: 0.15116961300373077\n",
            "epoch: 6 batch: 15 current batch loss: 0.18239480257034302\n",
            "epoch: 6 batch: 16 current batch loss: 0.1313772052526474\n",
            "epoch: 6 batch: 17 current batch loss: 0.12607483565807343\n",
            "epoch: 6 batch: 18 current batch loss: 0.16786034405231476\n",
            "epoch: 6 batch: 19 current batch loss: 0.13879846036434174\n",
            "epoch: 6 batch: 20 current batch loss: 0.1918785572052002\n",
            "epoch: 6 batch: 21 current batch loss: 0.14244942367076874\n",
            "epoch: 6 batch: 22 current batch loss: 0.15626206994056702\n",
            "epoch: 6 batch: 23 current batch loss: 0.15715458989143372\n",
            "epoch: 6 batch: 24 current batch loss: 0.17871885001659393\n",
            "epoch: 6 batch: 25 current batch loss: 0.15146572887897491\n",
            "epoch: 6 batch: 26 current batch loss: 0.12389859557151794\n",
            "epoch: 6 batch: 27 current batch loss: 0.11129043996334076\n",
            "epoch: 6 batch: 28 current batch loss: 0.09166325628757477\n",
            "epoch: 6 batch: 29 current batch loss: 0.09631093591451645\n",
            "epoch: 7 batch: 0 current batch loss: 0.15547548234462738\n",
            "epoch: 7 batch: 1 current batch loss: 0.0892031267285347\n",
            "epoch: 7 batch: 2 current batch loss: 0.13231094181537628\n",
            "epoch: 7 batch: 3 current batch loss: 0.1387651264667511\n",
            "epoch: 7 batch: 4 current batch loss: 0.1491728127002716\n",
            "epoch: 7 batch: 5 current batch loss: 0.12076377868652344\n",
            "epoch: 7 batch: 6 current batch loss: 0.15423879027366638\n",
            "epoch: 7 batch: 7 current batch loss: 0.14417316019535065\n",
            "epoch: 7 batch: 8 current batch loss: 0.12240739911794662\n",
            "epoch: 7 batch: 9 current batch loss: 0.1353062391281128\n",
            "epoch: 7 batch: 10 current batch loss: 0.15631568431854248\n",
            "epoch: 7 batch: 11 current batch loss: 0.10980583727359772\n",
            "epoch: 7 batch: 12 current batch loss: 0.14978909492492676\n",
            "epoch: 7 batch: 13 current batch loss: 0.16256870329380035\n",
            "epoch: 7 batch: 14 current batch loss: 0.12634563446044922\n",
            "epoch: 7 batch: 15 current batch loss: 0.1429930031299591\n",
            "epoch: 7 batch: 16 current batch loss: 0.10290984064340591\n",
            "epoch: 7 batch: 17 current batch loss: 0.11085956543684006\n",
            "epoch: 7 batch: 18 current batch loss: 0.14904293417930603\n",
            "epoch: 7 batch: 19 current batch loss: 0.11360087245702744\n",
            "epoch: 7 batch: 20 current batch loss: 0.15794819593429565\n",
            "epoch: 7 batch: 21 current batch loss: 0.12106066942214966\n",
            "epoch: 7 batch: 22 current batch loss: 0.14890921115875244\n",
            "epoch: 7 batch: 23 current batch loss: 0.12605586647987366\n",
            "epoch: 7 batch: 24 current batch loss: 0.14283698797225952\n",
            "epoch: 7 batch: 25 current batch loss: 0.13243557512760162\n",
            "epoch: 7 batch: 26 current batch loss: 0.098606176674366\n",
            "epoch: 7 batch: 27 current batch loss: 0.08553794771432877\n",
            "epoch: 7 batch: 28 current batch loss: 0.07776987552642822\n",
            "epoch: 7 batch: 29 current batch loss: 0.07957015186548233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In next cell we add scheduler. It will update learning rate after each epoch. Usually it improves network giving information on learning rate, which can show us if we didn't overtain our neural network as well."
      ],
      "metadata": {
        "id": "blIkraaOQt8Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26TeB4VdoHOs",
        "outputId": "9c6948b0-d4ed-4c8d-c89a-42c1ab5d8465"
      },
      "source": [
        "net_with_scheduler = MLP()\n",
        "optimizer = torch.optim.Adam(net_with_scheduler.parameters(), 0.001)   #initial learning rate of 0.001. \n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)    #updates the learning rate after each epoch. There are many ways to do that: \n",
        "                                                                                  #StepLR multiplies learning rate by gamma\n",
        "\n",
        "net_with_scheduler.train()\n",
        "for epoch in range(9):  #  an epoch is a training run through the whole data set\n",
        "\n",
        "    loss = 0.0\n",
        "    for batch, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "        #batch_inputs.squeeze(1)     #alternatively if not for a Flatten layer, squeeze() could be used to remove the second order of the tensor, \n",
        "                                      #the Channel, which is one-dimensional (this index can be equal to 0 only)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_outputs = net_with_scheduler(batch_inputs)\n",
        "        loss = torch.nn.functional.cross_entropy(batch_outputs, batch_labels, reduction = \"mean\")\n",
        "        print(\"epoch:\", epoch, \"batch:\", batch, \"current batch loss:\", loss.item(), \"current lr:\", scheduler.get_last_lr()[0]) \n",
        "        loss.backward()       #this computes gradients as we have seen in previous workshops\n",
        "        optimizer.step()     #but this line in fact updates our neural network. \n",
        "                                \n",
        "    scheduler.step()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 0 current batch loss: 2.3618810176849365 current lr: 0.001\n",
            "epoch: 0 batch: 1 current batch loss: 2.5173678398132324 current lr: 0.001\n",
            "epoch: 0 batch: 2 current batch loss: 2.4072515964508057 current lr: 0.001\n",
            "epoch: 0 batch: 3 current batch loss: 2.3458774089813232 current lr: 0.001\n",
            "epoch: 0 batch: 4 current batch loss: 2.320033073425293 current lr: 0.001\n",
            "epoch: 0 batch: 5 current batch loss: 2.3313136100769043 current lr: 0.001\n",
            "epoch: 0 batch: 6 current batch loss: 2.3503170013427734 current lr: 0.001\n",
            "epoch: 0 batch: 7 current batch loss: 2.341620445251465 current lr: 0.001\n",
            "epoch: 0 batch: 8 current batch loss: 2.3136448860168457 current lr: 0.001\n",
            "epoch: 0 batch: 9 current batch loss: 2.302180767059326 current lr: 0.001\n",
            "epoch: 0 batch: 10 current batch loss: 2.298361301422119 current lr: 0.001\n",
            "epoch: 0 batch: 11 current batch loss: 2.2976691722869873 current lr: 0.001\n",
            "epoch: 0 batch: 12 current batch loss: 2.2990074157714844 current lr: 0.001\n",
            "epoch: 0 batch: 13 current batch loss: 2.2950923442840576 current lr: 0.001\n",
            "epoch: 0 batch: 14 current batch loss: 2.30033278465271 current lr: 0.001\n",
            "epoch: 0 batch: 15 current batch loss: 2.289238452911377 current lr: 0.001\n",
            "epoch: 0 batch: 16 current batch loss: 2.2625463008880615 current lr: 0.001\n",
            "epoch: 0 batch: 17 current batch loss: 2.240618944168091 current lr: 0.001\n",
            "epoch: 0 batch: 18 current batch loss: 2.208620309829712 current lr: 0.001\n",
            "epoch: 0 batch: 19 current batch loss: 2.1637206077575684 current lr: 0.001\n",
            "epoch: 0 batch: 20 current batch loss: 2.1297554969787598 current lr: 0.001\n",
            "epoch: 0 batch: 21 current batch loss: 2.0820798873901367 current lr: 0.001\n",
            "epoch: 0 batch: 22 current batch loss: 2.0298306941986084 current lr: 0.001\n",
            "epoch: 0 batch: 23 current batch loss: 1.9847931861877441 current lr: 0.001\n",
            "epoch: 0 batch: 24 current batch loss: 1.9370235204696655 current lr: 0.001\n",
            "epoch: 0 batch: 25 current batch loss: 1.9031329154968262 current lr: 0.001\n",
            "epoch: 0 batch: 26 current batch loss: 1.8516496419906616 current lr: 0.001\n",
            "epoch: 0 batch: 27 current batch loss: 1.8071670532226562 current lr: 0.001\n",
            "epoch: 0 batch: 28 current batch loss: 1.7541722059249878 current lr: 0.001\n",
            "epoch: 0 batch: 29 current batch loss: 1.7276262044906616 current lr: 0.001\n",
            "epoch: 1 batch: 0 current batch loss: 1.692901849746704 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 1 current batch loss: 1.6555628776550293 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 2 current batch loss: 1.6070566177368164 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 3 current batch loss: 1.5801894664764404 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 4 current batch loss: 1.560296893119812 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 5 current batch loss: 1.5025527477264404 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 6 current batch loss: 1.53207266330719 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 7 current batch loss: 1.4961990118026733 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 8 current batch loss: 1.4256956577301025 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 9 current batch loss: 1.401490330696106 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 10 current batch loss: 1.3836089372634888 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 11 current batch loss: 1.3747138977050781 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 12 current batch loss: 1.3418151140213013 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 13 current batch loss: 1.3311469554901123 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 14 current batch loss: 1.3121814727783203 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 15 current batch loss: 1.3000105619430542 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 16 current batch loss: 1.2367089986801147 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 17 current batch loss: 1.2227429151535034 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 18 current batch loss: 1.224528431892395 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 19 current batch loss: 1.1778792142868042 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 20 current batch loss: 1.162456750869751 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 21 current batch loss: 1.1477453708648682 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 22 current batch loss: 1.1109367609024048 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 23 current batch loss: 1.0905382633209229 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 24 current batch loss: 1.0961209535598755 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 25 current batch loss: 1.0362378358840942 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 26 current batch loss: 1.0168296098709106 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 27 current batch loss: 0.9706351161003113 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 28 current batch loss: 0.9196920990943909 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 29 current batch loss: 0.8918754458427429 current lr: 0.0009000000000000001\n",
            "epoch: 2 batch: 0 current batch loss: 0.9282112121582031 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 1 current batch loss: 0.8749000430107117 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 2 current batch loss: 0.8670109510421753 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 3 current batch loss: 0.8818203806877136 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 4 current batch loss: 0.8845797777175903 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 5 current batch loss: 0.8464822173118591 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 6 current batch loss: 0.8618202209472656 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 7 current batch loss: 0.8637384176254272 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 8 current batch loss: 0.8065208196640015 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 9 current batch loss: 0.7481498718261719 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 10 current batch loss: 0.7520782947540283 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 11 current batch loss: 0.7360281944274902 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 12 current batch loss: 0.7473782896995544 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 13 current batch loss: 0.7523716688156128 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 14 current batch loss: 0.7271308302879333 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 15 current batch loss: 0.7453827857971191 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 16 current batch loss: 0.6597648859024048 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 17 current batch loss: 0.6215330362319946 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 18 current batch loss: 0.6905314922332764 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 19 current batch loss: 0.6460445523262024 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 20 current batch loss: 0.6850122809410095 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 21 current batch loss: 0.6001767516136169 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 22 current batch loss: 0.6013185381889343 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 23 current batch loss: 0.5922970175743103 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 24 current batch loss: 0.6238548159599304 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 25 current batch loss: 0.5886659026145935 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 26 current batch loss: 0.5415784120559692 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 27 current batch loss: 0.49237504601478577 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 28 current batch loss: 0.44776320457458496 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 29 current batch loss: 0.45294761657714844 current lr: 0.0008100000000000001\n",
            "epoch: 3 batch: 0 current batch loss: 0.5382193326950073 current lr: 0.000729\n",
            "epoch: 3 batch: 1 current batch loss: 0.45154422521591187 current lr: 0.000729\n",
            "epoch: 3 batch: 2 current batch loss: 0.47185054421424866 current lr: 0.000729\n",
            "epoch: 3 batch: 3 current batch loss: 0.49422821402549744 current lr: 0.000729\n",
            "epoch: 3 batch: 4 current batch loss: 0.5224425792694092 current lr: 0.000729\n",
            "epoch: 3 batch: 5 current batch loss: 0.48242345452308655 current lr: 0.000729\n",
            "epoch: 3 batch: 6 current batch loss: 0.5189685225486755 current lr: 0.000729\n",
            "epoch: 3 batch: 7 current batch loss: 0.4832485318183899 current lr: 0.000729\n",
            "epoch: 3 batch: 8 current batch loss: 0.46229004859924316 current lr: 0.000729\n",
            "epoch: 3 batch: 9 current batch loss: 0.4253753125667572 current lr: 0.000729\n",
            "epoch: 3 batch: 10 current batch loss: 0.43107983469963074 current lr: 0.000729\n",
            "epoch: 3 batch: 11 current batch loss: 0.41890284419059753 current lr: 0.000729\n",
            "epoch: 3 batch: 12 current batch loss: 0.44588011503219604 current lr: 0.000729\n",
            "epoch: 3 batch: 13 current batch loss: 0.4596485495567322 current lr: 0.000729\n",
            "epoch: 3 batch: 14 current batch loss: 0.4515780806541443 current lr: 0.000729\n",
            "epoch: 3 batch: 15 current batch loss: 0.4865206778049469 current lr: 0.000729\n",
            "epoch: 3 batch: 16 current batch loss: 0.3901459276676178 current lr: 0.000729\n",
            "epoch: 3 batch: 17 current batch loss: 0.3481884300708771 current lr: 0.000729\n",
            "epoch: 3 batch: 18 current batch loss: 0.4509230852127075 current lr: 0.000729\n",
            "epoch: 3 batch: 19 current batch loss: 0.40403661131858826 current lr: 0.000729\n",
            "epoch: 3 batch: 20 current batch loss: 0.4548780024051666 current lr: 0.000729\n",
            "epoch: 3 batch: 21 current batch loss: 0.36007264256477356 current lr: 0.000729\n",
            "epoch: 3 batch: 22 current batch loss: 0.39197954535484314 current lr: 0.000729\n",
            "epoch: 3 batch: 23 current batch loss: 0.38639768958091736 current lr: 0.000729\n",
            "epoch: 3 batch: 24 current batch loss: 0.4255264401435852 current lr: 0.000729\n",
            "epoch: 3 batch: 25 current batch loss: 0.40836164355278015 current lr: 0.000729\n",
            "epoch: 3 batch: 26 current batch loss: 0.36354169249534607 current lr: 0.000729\n",
            "epoch: 3 batch: 27 current batch loss: 0.3052018880844116 current lr: 0.000729\n",
            "epoch: 3 batch: 28 current batch loss: 0.27315589785575867 current lr: 0.000729\n",
            "epoch: 3 batch: 29 current batch loss: 0.2722041606903076 current lr: 0.000729\n",
            "epoch: 4 batch: 0 current batch loss: 0.3766483664512634 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 1 current batch loss: 0.28459393978118896 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 2 current batch loss: 0.32352733612060547 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 3 current batch loss: 0.3477475643157959 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 4 current batch loss: 0.38443297147750854 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 5 current batch loss: 0.344695121049881 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 6 current batch loss: 0.38756608963012695 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 7 current batch loss: 0.3622336983680725 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 8 current batch loss: 0.34367963671684265 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 9 current batch loss: 0.2983839511871338 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 10 current batch loss: 0.3160281479358673 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 11 current batch loss: 0.31773102283477783 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 12 current batch loss: 0.3502471148967743 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 13 current batch loss: 0.360834538936615 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 14 current batch loss: 0.3400503098964691 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 15 current batch loss: 0.37646204233169556 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 16 current batch loss: 0.30030950903892517 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 17 current batch loss: 0.26577818393707275 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 18 current batch loss: 0.35009026527404785 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 19 current batch loss: 0.32428377866744995 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 20 current batch loss: 0.37346750497817993 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 21 current batch loss: 0.28314265608787537 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 22 current batch loss: 0.30618295073509216 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 23 current batch loss: 0.32348334789276123 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 24 current batch loss: 0.3643682897090912 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 25 current batch loss: 0.29759934544563293 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 26 current batch loss: 0.2916457951068878 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 27 current batch loss: 0.2345261424779892 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 28 current batch loss: 0.2094712257385254 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 29 current batch loss: 0.20813806354999542 current lr: 0.0006561000000000001\n",
            "epoch: 5 batch: 0 current batch loss: 0.31606075167655945 current lr: 0.00059049\n",
            "epoch: 5 batch: 1 current batch loss: 0.2273114174604416 current lr: 0.00059049\n",
            "epoch: 5 batch: 2 current batch loss: 0.2599375545978546 current lr: 0.00059049\n",
            "epoch: 5 batch: 3 current batch loss: 0.28679829835891724 current lr: 0.00059049\n",
            "epoch: 5 batch: 4 current batch loss: 0.30953413248062134 current lr: 0.00059049\n",
            "epoch: 5 batch: 5 current batch loss: 0.27103373408317566 current lr: 0.00059049\n",
            "epoch: 5 batch: 6 current batch loss: 0.31822463870048523 current lr: 0.00059049\n",
            "epoch: 5 batch: 7 current batch loss: 0.2991325557231903 current lr: 0.00059049\n",
            "epoch: 5 batch: 8 current batch loss: 0.2774481177330017 current lr: 0.00059049\n",
            "epoch: 5 batch: 9 current batch loss: 0.2468157857656479 current lr: 0.00059049\n",
            "epoch: 5 batch: 10 current batch loss: 0.2666304409503937 current lr: 0.00059049\n",
            "epoch: 5 batch: 11 current batch loss: 0.24437107145786285 current lr: 0.00059049\n",
            "epoch: 5 batch: 12 current batch loss: 0.2833167612552643 current lr: 0.00059049\n",
            "epoch: 5 batch: 13 current batch loss: 0.30226609110832214 current lr: 0.00059049\n",
            "epoch: 5 batch: 14 current batch loss: 0.27508631348609924 current lr: 0.00059049\n",
            "epoch: 5 batch: 15 current batch loss: 0.30489489436149597 current lr: 0.00059049\n",
            "epoch: 5 batch: 16 current batch loss: 0.23902536928653717 current lr: 0.00059049\n",
            "epoch: 5 batch: 17 current batch loss: 0.2158462107181549 current lr: 0.00059049\n",
            "epoch: 5 batch: 18 current batch loss: 0.2907988429069519 current lr: 0.00059049\n",
            "epoch: 5 batch: 19 current batch loss: 0.24752360582351685 current lr: 0.00059049\n",
            "epoch: 5 batch: 20 current batch loss: 0.2924751341342926 current lr: 0.00059049\n",
            "epoch: 5 batch: 21 current batch loss: 0.23293133080005646 current lr: 0.00059049\n",
            "epoch: 5 batch: 22 current batch loss: 0.2560156583786011 current lr: 0.00059049\n",
            "epoch: 5 batch: 23 current batch loss: 0.2608029246330261 current lr: 0.00059049\n",
            "epoch: 5 batch: 24 current batch loss: 0.2962448298931122 current lr: 0.00059049\n",
            "epoch: 5 batch: 25 current batch loss: 0.24057041108608246 current lr: 0.00059049\n",
            "epoch: 5 batch: 26 current batch loss: 0.23614689707756042 current lr: 0.00059049\n",
            "epoch: 5 batch: 27 current batch loss: 0.18632149696350098 current lr: 0.00059049\n",
            "epoch: 5 batch: 28 current batch loss: 0.17956894636154175 current lr: 0.00059049\n",
            "epoch: 5 batch: 29 current batch loss: 0.17225472629070282 current lr: 0.00059049\n",
            "epoch: 6 batch: 0 current batch loss: 0.26397353410720825 current lr: 0.000531441\n",
            "epoch: 6 batch: 1 current batch loss: 0.1770952194929123 current lr: 0.000531441\n",
            "epoch: 6 batch: 2 current batch loss: 0.21943731606006622 current lr: 0.000531441\n",
            "epoch: 6 batch: 3 current batch loss: 0.2446480542421341 current lr: 0.000531441\n",
            "epoch: 6 batch: 4 current batch loss: 0.2633143961429596 current lr: 0.000531441\n",
            "epoch: 6 batch: 5 current batch loss: 0.21999545395374298 current lr: 0.000531441\n",
            "epoch: 6 batch: 6 current batch loss: 0.2522895634174347 current lr: 0.000531441\n",
            "epoch: 6 batch: 7 current batch loss: 0.24856390058994293 current lr: 0.000531441\n",
            "epoch: 6 batch: 8 current batch loss: 0.2361251413822174 current lr: 0.000531441\n",
            "epoch: 6 batch: 9 current batch loss: 0.20954357087612152 current lr: 0.000531441\n",
            "epoch: 6 batch: 10 current batch loss: 0.2239939570426941 current lr: 0.000531441\n",
            "epoch: 6 batch: 11 current batch loss: 0.2053629606962204 current lr: 0.000531441\n",
            "epoch: 6 batch: 12 current batch loss: 0.23653216660022736 current lr: 0.000531441\n",
            "epoch: 6 batch: 13 current batch loss: 0.25830042362213135 current lr: 0.000531441\n",
            "epoch: 6 batch: 14 current batch loss: 0.22651827335357666 current lr: 0.000531441\n",
            "epoch: 6 batch: 15 current batch loss: 0.25444671511650085 current lr: 0.000531441\n",
            "epoch: 6 batch: 16 current batch loss: 0.19843418896198273 current lr: 0.000531441\n",
            "epoch: 6 batch: 17 current batch loss: 0.18617196381092072 current lr: 0.000531441\n",
            "epoch: 6 batch: 18 current batch loss: 0.2484511137008667 current lr: 0.000531441\n",
            "epoch: 6 batch: 19 current batch loss: 0.21152855455875397 current lr: 0.000531441\n",
            "epoch: 6 batch: 20 current batch loss: 0.25183820724487305 current lr: 0.000531441\n",
            "epoch: 6 batch: 21 current batch loss: 0.19701260328292847 current lr: 0.000531441\n",
            "epoch: 6 batch: 22 current batch loss: 0.21749846637248993 current lr: 0.000531441\n",
            "epoch: 6 batch: 23 current batch loss: 0.2270389199256897 current lr: 0.000531441\n",
            "epoch: 6 batch: 24 current batch loss: 0.259117990732193 current lr: 0.000531441\n",
            "epoch: 6 batch: 25 current batch loss: 0.20371437072753906 current lr: 0.000531441\n",
            "epoch: 6 batch: 26 current batch loss: 0.19886404275894165 current lr: 0.000531441\n",
            "epoch: 6 batch: 27 current batch loss: 0.15723486244678497 current lr: 0.000531441\n",
            "epoch: 6 batch: 28 current batch loss: 0.15103542804718018 current lr: 0.000531441\n",
            "epoch: 6 batch: 29 current batch loss: 0.1472388356924057 current lr: 0.000531441\n",
            "epoch: 7 batch: 0 current batch loss: 0.23044492304325104 current lr: 0.0004782969\n",
            "epoch: 7 batch: 1 current batch loss: 0.14548376202583313 current lr: 0.0004782969\n",
            "epoch: 7 batch: 2 current batch loss: 0.1883745789527893 current lr: 0.0004782969\n",
            "epoch: 7 batch: 3 current batch loss: 0.21221467852592468 current lr: 0.0004782969\n",
            "epoch: 7 batch: 4 current batch loss: 0.23039402067661285 current lr: 0.0004782969\n",
            "epoch: 7 batch: 5 current batch loss: 0.18696202337741852 current lr: 0.0004782969\n",
            "epoch: 7 batch: 6 current batch loss: 0.21264411509037018 current lr: 0.0004782969\n",
            "epoch: 7 batch: 7 current batch loss: 0.21295174956321716 current lr: 0.0004782969\n",
            "epoch: 7 batch: 8 current batch loss: 0.2026473879814148 current lr: 0.0004782969\n",
            "epoch: 7 batch: 9 current batch loss: 0.1842980533838272 current lr: 0.0004782969\n",
            "epoch: 7 batch: 10 current batch loss: 0.19699493050575256 current lr: 0.0004782969\n",
            "epoch: 7 batch: 11 current batch loss: 0.17607341706752777 current lr: 0.0004782969\n",
            "epoch: 7 batch: 12 current batch loss: 0.20906676352024078 current lr: 0.0004782969\n",
            "epoch: 7 batch: 13 current batch loss: 0.2263643443584442 current lr: 0.0004782969\n",
            "epoch: 7 batch: 14 current batch loss: 0.19262713193893433 current lr: 0.0004782969\n",
            "epoch: 7 batch: 15 current batch loss: 0.21734574437141418 current lr: 0.0004782969\n",
            "epoch: 7 batch: 16 current batch loss: 0.1708199679851532 current lr: 0.0004782969\n",
            "epoch: 7 batch: 17 current batch loss: 0.1627291887998581 current lr: 0.0004782969\n",
            "epoch: 7 batch: 18 current batch loss: 0.21874193847179413 current lr: 0.0004782969\n",
            "epoch: 7 batch: 19 current batch loss: 0.1823330968618393 current lr: 0.0004782969\n",
            "epoch: 7 batch: 20 current batch loss: 0.22202496230602264 current lr: 0.0004782969\n",
            "epoch: 7 batch: 21 current batch loss: 0.1725669950246811 current lr: 0.0004782969\n",
            "epoch: 7 batch: 22 current batch loss: 0.19286809861660004 current lr: 0.0004782969\n",
            "epoch: 7 batch: 23 current batch loss: 0.199865460395813 current lr: 0.0004782969\n",
            "epoch: 7 batch: 24 current batch loss: 0.22760820388793945 current lr: 0.0004782969\n",
            "epoch: 7 batch: 25 current batch loss: 0.17692053318023682 current lr: 0.0004782969\n",
            "epoch: 7 batch: 26 current batch loss: 0.1709321290254593 current lr: 0.0004782969\n",
            "epoch: 7 batch: 27 current batch loss: 0.13731679320335388 current lr: 0.0004782969\n",
            "epoch: 7 batch: 28 current batch loss: 0.1333909034729004 current lr: 0.0004782969\n",
            "epoch: 7 batch: 29 current batch loss: 0.1316457986831665 current lr: 0.0004782969\n",
            "epoch: 8 batch: 0 current batch loss: 0.2080892026424408 current lr: 0.00043046721\n",
            "epoch: 8 batch: 1 current batch loss: 0.1231011226773262 current lr: 0.00043046721\n",
            "epoch: 8 batch: 2 current batch loss: 0.1670209765434265 current lr: 0.00043046721\n",
            "epoch: 8 batch: 3 current batch loss: 0.18465019762516022 current lr: 0.00043046721\n",
            "epoch: 8 batch: 4 current batch loss: 0.2028069645166397 current lr: 0.00043046721\n",
            "epoch: 8 batch: 5 current batch loss: 0.16287840902805328 current lr: 0.00043046721\n",
            "epoch: 8 batch: 6 current batch loss: 0.18570013344287872 current lr: 0.00043046721\n",
            "epoch: 8 batch: 7 current batch loss: 0.18590141832828522 current lr: 0.00043046721\n",
            "epoch: 8 batch: 8 current batch loss: 0.1792302131652832 current lr: 0.00043046721\n",
            "epoch: 8 batch: 9 current batch loss: 0.16586869955062866 current lr: 0.00043046721\n",
            "epoch: 8 batch: 10 current batch loss: 0.1756887435913086 current lr: 0.00043046721\n",
            "epoch: 8 batch: 11 current batch loss: 0.15401031076908112 current lr: 0.00043046721\n",
            "epoch: 8 batch: 12 current batch loss: 0.18661218881607056 current lr: 0.00043046721\n",
            "epoch: 8 batch: 13 current batch loss: 0.2015327513217926 current lr: 0.00043046721\n",
            "epoch: 8 batch: 14 current batch loss: 0.168931245803833 current lr: 0.00043046721\n",
            "epoch: 8 batch: 15 current batch loss: 0.19170762598514557 current lr: 0.00043046721\n",
            "epoch: 8 batch: 16 current batch loss: 0.1507841944694519 current lr: 0.00043046721\n",
            "epoch: 8 batch: 17 current batch loss: 0.1465080827474594 current lr: 0.00043046721\n",
            "epoch: 8 batch: 18 current batch loss: 0.19619649648666382 current lr: 0.00043046721\n",
            "epoch: 8 batch: 19 current batch loss: 0.15959525108337402 current lr: 0.00043046721\n",
            "epoch: 8 batch: 20 current batch loss: 0.1982341706752777 current lr: 0.00043046721\n",
            "epoch: 8 batch: 21 current batch loss: 0.15472760796546936 current lr: 0.00043046721\n",
            "epoch: 8 batch: 22 current batch loss: 0.17435745894908905 current lr: 0.00043046721\n",
            "epoch: 8 batch: 23 current batch loss: 0.17885135114192963 current lr: 0.00043046721\n",
            "epoch: 8 batch: 24 current batch loss: 0.2044091373682022 current lr: 0.00043046721\n",
            "epoch: 8 batch: 25 current batch loss: 0.15792004764080048 current lr: 0.00043046721\n",
            "epoch: 8 batch: 26 current batch loss: 0.14951153099536896 current lr: 0.00043046721\n",
            "epoch: 8 batch: 27 current batch loss: 0.12082407623529434 current lr: 0.00043046721\n",
            "epoch: 8 batch: 28 current batch loss: 0.11899441480636597 current lr: 0.00043046721\n",
            "epoch: 8 batch: 29 current batch loss: 0.12004747986793518 current lr: 0.00043046721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have built our networks. No we can see how accurate they actually are. To do that we will use simple method. Check how many accurate results we got and divide it by all samples. We will check how it went without and with sheduler."
      ],
      "metadata": {
        "id": "FP-kqoOoR0JD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXLgdK7RsPWY",
        "outputId": "614bc572-2a1b-4892-cf91-cb4be13a7427"
      },
      "source": [
        "good = 0\n",
        "wrong = 0\n",
        "\n",
        "net.eval()   #it prevents that the net learns during evalution. The gradients are not computed, so this makes it faster, too\n",
        "#batches in test are of size 1\n",
        "for batch, data in enumerate(testloader):\n",
        "    datapoint, label = data\n",
        "    \n",
        "    prediction = net(datapoint)                  #prediction has values representing the \"prevalence\" of the corresponding class\n",
        "    classification = torch.argmax(prediction)    #the class is the index of maximal \"prevalence\"\n",
        "    \n",
        "    if classification.item() == label.item():\n",
        "        good += 1\n",
        "    else:\n",
        "        wrong += 1\n",
        "        \n",
        "print(\"accuracy = \", good/(good+wrong))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.9615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7WdBmZmsVtm",
        "outputId": "4783a44b-ec98-43ad-ea89-0a8881d955e5"
      },
      "source": [
        "good = 0\n",
        "wrong = 0\n",
        "\n",
        "net_with_scheduler.eval()   #it prevents that the net learns during evalution. The gradients are not computed, so this makes it faster, too\n",
        "#batches in test are of size 1\n",
        "for batch, data in enumerate(testloader):\n",
        "    datapoint, label = data\n",
        "    \n",
        "    prediction = net_with_scheduler(datapoint)                  #prediction has values representing the \"prevalence\" of the corresponding class\n",
        "    classification = torch.argmax(prediction)                   #the class is the index of maximal \"prevalence\"\n",
        "    \n",
        "    if classification.item() == label.item():\n",
        "        good += 1\n",
        "    else:\n",
        "        wrong += 1\n",
        "        \n",
        "print(\"accuracy = \", good/(good+wrong))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.9508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results are quite good. Both methods got over 95% accuracy. To improve it even more we can change number of perceptrons, sheduler properities and activation method."
      ],
      "metadata": {
        "id": "Hbg7c6PeS3Cr"
      }
    }
  ]
}